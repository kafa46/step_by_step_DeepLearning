{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 차근차근 딥러닝 Part 04. 딥러닝 회귀 - Step 05. 딥러닝 회귀 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston_house = load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 전처리\n",
    "- pandas를 이용하여 데이터를 로딩하고, 설명변수와 타겟변수를 합치기\n",
    "- StandardScaler를 이용하여 정규화 해주기(이때 타켓 변수는 제외)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.075562</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.492439</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>-1.208727</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>-1.361517</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.026501</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>-0.413229</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>0.439316</td>\n",
       "      <td>0.018673</td>\n",
       "      <td>-0.625796</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.803212</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.387217</td>\n",
       "      <td>-0.418147</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>-0.415249</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>-0.234548</td>\n",
       "      <td>0.288933</td>\n",
       "      <td>-0.716639</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.803212</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.500850</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>-0.413447</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>0.984960</td>\n",
       "      <td>0.797449</td>\n",
       "      <td>-0.773684</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.803212</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.983048</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>-0.407764</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>0.725672</td>\n",
       "      <td>0.736996</td>\n",
       "      <td>-0.668437</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.803212</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.403225</td>\n",
       "      <td>-0.865302</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>-0.415000</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>-0.362767</td>\n",
       "      <td>0.434732</td>\n",
       "      <td>-0.613246</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.803212</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.669058</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0   -0.419782  0.284830 -1.287909 -0.272599 -0.144217  0.413672 -0.120013   \n",
       "1   -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.194274  0.367166   \n",
       "2   -0.417342 -0.487722 -0.593381 -0.272599 -0.740262  1.282714 -0.265812   \n",
       "3   -0.416750 -0.487722 -1.306878 -0.272599 -0.835284  1.016303 -0.809889   \n",
       "4   -0.412482 -0.487722 -1.306878 -0.272599 -0.835284  1.228577 -0.511180   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "501 -0.413229 -0.487722  0.115738 -0.272599  0.158124  0.439316  0.018673   \n",
       "502 -0.415249 -0.487722  0.115738 -0.272599  0.158124 -0.234548  0.288933   \n",
       "503 -0.413447 -0.487722  0.115738 -0.272599  0.158124  0.984960  0.797449   \n",
       "504 -0.407764 -0.487722  0.115738 -0.272599  0.158124  0.725672  0.736996   \n",
       "505 -0.415000 -0.487722  0.115738 -0.272599  0.158124 -0.362767  0.434732   \n",
       "\n",
       "          DIS       RAD       TAX   PTRATIO         B     LSTAT  TARGET  \n",
       "0    0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562    24.0  \n",
       "1    0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439    21.6  \n",
       "2    0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727    34.7  \n",
       "3    1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517    33.4  \n",
       "4    1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501    36.2  \n",
       "..        ...       ...       ...       ...       ...       ...     ...  \n",
       "501 -0.625796 -0.982843 -0.803212  1.176466  0.387217 -0.418147    22.4  \n",
       "502 -0.716639 -0.982843 -0.803212  1.176466  0.441052 -0.500850    20.6  \n",
       "503 -0.773684 -0.982843 -0.803212  1.176466  0.441052 -0.983048    23.9  \n",
       "504 -0.668437 -0.982843 -0.803212  1.176466  0.403225 -0.865302    22.0  \n",
       "505 -0.613246 -0.982843 -0.803212  1.176466  0.441052 -0.669058    11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.DataFrame(boston_house.data, columns=boston_house.feature_names)\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df.values[:,:])\n",
    "df.values[:,:] = scaler.transform(df.values[:,:])\n",
    "\n",
    "# 타겟 변수를 마지막에 추가하기\n",
    "df['TARGET'] = boston_house.target\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 데이터셋 분할 $\\to$ Train, Valid, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "data_numpy = torch.from_numpy(df.values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([506, 13]) torch.Size([506, 1])\n"
     ]
    }
   ],
   "source": [
    "x = data_numpy[:, :-1] # 독립 변수\n",
    "y = data_numpy[:, -1:] # 타겟 변수\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / Validation / Test 분할 비율\n",
    "split_ratio = [0.6, 0.2, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 303, Valid: 101, Test: 102 samples.\n"
     ]
    }
   ],
   "source": [
    "# 분할 데이터별 필요한 데이터 수 설정\n",
    "train_cnt = int(data_numpy.size(0) * split_ratio[0])\n",
    "valid_cnt = int(data_numpy.size(0) * split_ratio[1])\n",
    "test_cnt = data_numpy.size(0) - train_cnt - valid_cnt\n",
    "cnts = [train_cnt, valid_cnt, test_cnt]\n",
    "\n",
    "# 분할 결과를 확인하기 위해 화면에 출력\n",
    "print(\"Train: {}, Valid: {}, Test: {} samples.\".format(\n",
    "                                train_cnt, \n",
    "                                valid_cnt, \n",
    "                                test_cnt)\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([303, 13]) torch.Size([303, 1])\n",
      "torch.Size([101, 13]) torch.Size([101, 1])\n",
      "torch.Size([102, 13]) torch.Size([102, 1])\n"
     ]
    }
   ],
   "source": [
    "### 랜덤하게 데이터를 추출하여 Train / Validation / Test 구성 ###\n",
    "\n",
    "# 데이터 갯수 만큼 랜덤하게 인덱스 번호 생성\n",
    "indices = torch.randperm(data_numpy.size(0))\n",
    "\n",
    "# 독립변수(x)와 타겟변수(y)로부터 랜덤하게 생성한 인덱스(indices) 순서대로 추출\n",
    "x = torch.index_select(x, dim=0, index=indices)\n",
    "y = torch.index_select(y, dim=0, index=indices)\n",
    "\n",
    "# Train / Validation / Test 분할 비율에 맞게 데이터 분할\n",
    "x = x.split(cnts, dim=0)\n",
    "y = y.split(cnts, dim=0)\n",
    "\n",
    "# 분할된 데이터셋 크기 확인\n",
    "for x_i, y_i in zip(x, y):\n",
    "    print(x_i.size(), y_i.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([303, 13]), torch.Size([303, 1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape, y[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. 딥러닝 모델 생성 1. Pytorch의 nn.Module 활용하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# 딥러닝 모델 생성 1. Pytorch의 nn.Module 활용하는 방법\n",
    "class MyModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        self.input_dim = input_dim # 입력 차원\n",
    "        self.output_dim = output_dim # 출력 차원\n",
    "        \n",
    "        super().__init__() # 부모 클래스 __init__ 보호\n",
    "        \n",
    "        # 은닉층(Hidden Layer) 설계\n",
    "        self.linear1 = nn.Linear(input_dim, 32)\n",
    "        self.linear2 = nn.Linear(32, 16)\n",
    "        self.linear3 = nn.Linear(16, 8)\n",
    "        self.linear4 = nn.Linear(8, 4)\n",
    "        self.linear5 = nn.Linear(4, output_dim)\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # 객체 호출 시 입력 텐서 크기: |x| = (batch_size, input_dim)\n",
    "        h = self.act(self.linear1(x)) # |h| = (batch_size, 32)\n",
    "        h = self.act(self.linear2(h))\n",
    "        h = self.act(self.linear3(h))\n",
    "        h = self.act(self.linear4(h))\n",
    "        y = self.linear5(h)\n",
    "        # 출력텐서 크기: |y| = (batch_size, output_dim)\n",
    "        \n",
    "        # 구축된 신경망 반환(return)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 딥러닝 모델 생성 2. Pytorch의 nn.Sequential을 활용하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=13, out_features=5, bias=True)\n",
      "  (1): LeakyReLU(negative_slope=0.01)\n",
      "  (2): Linear(in_features=5, out_features=5, bias=True)\n",
      "  (3): LeakyReLU(negative_slope=0.01)\n",
      "  (4): Linear(in_features=5, out_features=5, bias=True)\n",
      "  (5): LeakyReLU(negative_slope=0.01)\n",
      "  (6): Linear(in_features=5, out_features=5, bias=True)\n",
      "  (7): LeakyReLU(negative_slope=0.01)\n",
      "  (8): Linear(in_features=5, out_features=5, bias=True)\n",
      "  (9): LeakyReLU(negative_slope=0.01)\n",
      "  (10): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Pytorch의 nn.Sequential을 활용하는 방법\n",
    "input_dim = x[0].size(-1)\n",
    "ouput_dim = y[0].size(-1)\n",
    "model_sequential = nn.Sequential(\n",
    "    nn.Linear(input_dim, 5),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(5, 5),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(5, 5),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(5, 5),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(5, 5),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(5, ouput_dim),\n",
    ")\n",
    "\n",
    "# 네트워크 형태 확인을 위해 화면에 모델을 출력\n",
    "print(model_sequential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.학습(Train) 함수 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 모델 저장을 위한 deepcopy 라이브러리 임포트\n",
    "from copy import deepcopy\n",
    "\n",
    "def train(\n",
    "    model, # 신경망 모델\n",
    "    x, # 학습데이트\n",
    "    y, # 예측값(정답)\n",
    "    loss_func, # 손실함수\n",
    "    lr=1e-4, # 학습률\n",
    "    n_epochs=100, # Epoch 수행 횟수\n",
    "    batch_size=32, # 미니배치 크기\n",
    "    print_interval=1000, # 학습결과를 출력하는 간격\n",
    "):\n",
    "\n",
    "    lowest_loss = np.inf\n",
    "    best_model = None\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    \n",
    "    # GPU 사용이 가능할 경우 사용, 불가능할 경우 CPU 사용\n",
    "    device = torch.device('cpu')\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    \n",
    "    # 학습 시작 전 모든 값을 지정된 Device로 이동\n",
    "    model = model.to(device)\n",
    "    x = [x_i.to(device) for x_i in x]\n",
    "    y = [y_i.to(device) for y_i in y]\n",
    "    \n",
    "    ### 학습 및 검증 시작 ###\n",
    "    # 학습 진행상태(Loss)를 시각화하기 위한 List todtjd\n",
    "    train_history = []\n",
    "    valid_history = []\n",
    "    \n",
    "    ### Epoch 시작 ###\n",
    "    for epoch_index in range(n_epochs):\n",
    "        \n",
    "        '''\n",
    "        우리 예제의 경우 텐서 형태\n",
    "        x[0]: x_1, y_1 -> torch.Size([303, 13]) torch.Size([303, 1])\n",
    "        x[1]: x_2, y_2 -> torch.Size([101, 13]) torch.Size([101, 1])\n",
    "        x[2]: x_3, y_3 -> torch.Size([102, 13]) torch.Size([102, 1])\n",
    "        '''\n",
    "        \n",
    "        train_x, train_y = x[0], y[0]\n",
    "        valid_x, valid_y = x[1], y[1]\n",
    "        test_x, test_y = x[2], y[2]\n",
    "        \n",
    "        # 미니배치 만들기 x[0], y[0] --> train set\n",
    "        indices= torch.randperm(train_x.size(0), device=train_x.device)\n",
    "        train_x = torch.index_select(train_x, dim=0, index=indices)\n",
    "        train_y = torch.index_select(train_y, dim=0, index=indices)\n",
    "        train_x_batch = torch.split(train_x, batch_size, dim=0)\n",
    "        train_y_batch = torch.split(train_y, batch_size, dim=0)\n",
    "        \n",
    "        # 개별 |train_x_batch| = (batch_size, input_dim)\n",
    "\n",
    "        ### Train 데이터 학습 시작 ###\n",
    "        model.train() # 학습모드 On\n",
    "        total_loss_train = 0\n",
    "        for batch_index in range(len(train_x_batch)):\n",
    "            \n",
    "            # 텐서 형태\n",
    "            # |x_i| = (batch_size, 13)\n",
    "            # |y_i| = (batch_size, 1)\n",
    "            \n",
    "            # 전진(forward) 학습 \n",
    "            y_hat = model(train_x_batch[batch_index])\n",
    "\n",
    "            # 손실값 계산\n",
    "            loss = loss_func(y_hat, train_y_batch[batch_index])\n",
    "\n",
    "            # 미분 수행 (back propagation)\n",
    "            optimizer.zero_grad() # 기존 미분값이 있다면 초기화\n",
    "            loss.backward()\n",
    "        \n",
    "            # Stochastic Gradient Descent 수행\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Total Loss 업데이트\n",
    "            total_loss_train += float(loss) \n",
    "        \n",
    "        # 최종 Train Loss 계산 -> Train 종료\n",
    "        train_loss = total_loss_train / len(train_x_batch)\n",
    "        \n",
    "        ### Validation 시작 ###\n",
    "        model.eval() # 학습모드 off\n",
    "        with torch.no_grad():\n",
    "            y_hat = model(valid_x)\n",
    "            loss = loss_func(y_hat, valid_y)\n",
    "            valid_loss = loss / len(valid_y)\n",
    "\n",
    "        # Valid Loss를 확인하여 모델을 저장\n",
    "        if valid_loss <= lowest_loss:\n",
    "            lowest_loss = valid_loss\n",
    "            best_model = deepcopy(model.state_dict())\n",
    "            torch.save(\n",
    "                {\n",
    "                    'model': best_model,\n",
    "                    'n_epochs': n_epochs,\n",
    "                    'batch_size': batch_size,\n",
    "                    'lr': lr,\n",
    "                    'optimizer': 'SGD',\n",
    "                }, \n",
    "                'model_regression.pth'\n",
    "            )\n",
    "            \n",
    "        # 1회 epoch 종료 후 Loss 출력\n",
    "        if (epoch_index + 1) % print_interval == 0:\n",
    "            print(\n",
    "                'Epoch({0:2d}/{1:2d}): train_loss={2:8.6f}  valid_loss={3:8.6f}  lowest_loss={4:8.6f}'.format(\n",
    "                    epoch_index+1, \n",
    "                    n_epochs,\n",
    "                    train_loss,\n",
    "                    valid_loss,\n",
    "                    lowest_loss,               \n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train, valid 데이터를 이용하여 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터\n",
    "batch_size = 32\n",
    "n_epochs = 10000\n",
    "print_interval = 1000\n",
    "learning_rate = 1e-4\n",
    "model_MyModel = MyModel(x[0].size(-1), y[0].size(-1))\n",
    "model_sequential\n",
    "loss_func = F.mse_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. nn.Module을 사용한 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch(1000/10000): train_loss=3.693047  valid_loss=0.162697  lowest_loss=0.160925\n",
      "Epoch(2000/10000): train_loss=2.069057  valid_loss=0.154008  lowest_loss=0.151120\n",
      "Epoch(3000/10000): train_loss=1.219060  valid_loss=0.154911  lowest_loss=0.149705\n",
      "Epoch(4000/10000): train_loss=0.883124  valid_loss=0.166389  lowest_loss=0.149705\n",
      "Epoch(5000/10000): train_loss=0.757545  valid_loss=0.171784  lowest_loss=0.149705\n",
      "Epoch(6000/10000): train_loss=0.583953  valid_loss=0.172766  lowest_loss=0.149705\n",
      "Epoch(7000/10000): train_loss=0.534458  valid_loss=0.171277  lowest_loss=0.149705\n",
      "Epoch(8000/10000): train_loss=0.483372  valid_loss=0.174632  lowest_loss=0.149705\n",
      "Epoch(9000/10000): train_loss=0.414599  valid_loss=0.177102  lowest_loss=0.149705\n",
      "Epoch(10000/10000): train_loss=0.367553  valid_loss=0.178229  lowest_loss=0.149705\n"
     ]
    }
   ],
   "source": [
    "train(model_MyModel, x, y, loss_func, n_epochs=n_epochs, batch_size=batch_size, print_interval=print_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. nn.Sequential을 사용한 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train(model_sequencial, x, y, loss_func, n_epochs=n_epochs, batch_size=batch_size, print_interval=print_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test 데이터 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_epochs = check_point['n_epochs']\n",
    "# batch_size = check_point['batch_size']\n",
    "# lr = check_point['lr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. nn.Module을 사용할 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nn.Module을 상속받은 클래스를 이용하여 빈 모델 생성\n",
    "model = MyModel(x[0].size(-1), y[0].size(-1))\n",
    "\n",
    "# model.pth 파일 정보를 업로드하여 check_point 변수에 저장\n",
    "check_point = torch.load('./model_regression.pth')\n",
    "\n",
    "# model.pth에 저장된 학습 파라미터를 model에 업로드\n",
    "model.load_state_dict(check_point['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2. nn.Sequential을 사용할 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터가 적재되지 않은 초기 모델 생성\n",
    "# input_dim = x[0].size(-1)\n",
    "# ouput_dim = y[0].size(-1)\n",
    "# model_sequencial = nn.Sequential(\n",
    "#     nn.Linear(input_dim, 5),\n",
    "#     nn.LeakyReLU(),\n",
    "#     nn.Linear(5, 5),\n",
    "#     nn.LeakyReLU(),\n",
    "#     nn.Linear(5, 5),\n",
    "#     nn.LeakyReLU(),\n",
    "#     nn.Linear(5, 5),\n",
    "#     nn.LeakyReLU(),\n",
    "#     nn.Linear(5, 5),\n",
    "#     nn.LeakyReLU(),\n",
    "#     nn.Linear(5, ouput_dim),\n",
    "# )\n",
    "\n",
    "# 저장된 모델 파일을 이용하여 모델에 파라미터 적재\n",
    "# model.load_state_dict(check_point['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 예측 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             y      y_hat\n",
      "0    26.400000  25.477537\n",
      "1    36.200001  33.777271\n",
      "2    22.400000  24.002289\n",
      "3    21.700001  23.472151\n",
      "4    20.500000  18.415392\n",
      "..         ...        ...\n",
      "97   22.600000  21.904406\n",
      "98   24.299999  23.139069\n",
      "99   19.400000  20.886578\n",
      "100  50.000000  39.385952\n",
      "101  23.299999  24.450533\n",
      "\n",
      "[102 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 예측값과 실제값을 표로 비교\n",
    "y_hat = model(x[2])\n",
    "y = y[2]\n",
    "df = pd.DataFrame(torch.cat([y, y_hat], dim=1).detach().numpy(),\n",
    "                  columns=[\"y\", \"y_hat\"])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 시각화\n",
    "import seaborn as sns\n",
    "sns.pairplot(df, height=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 7.812567018995098\n"
     ]
    }
   ],
   "source": [
    "mse = np.sum((y.detach().numpy() - y_hat.detach().numpy())**2 ) / y.size(0)\n",
    "print('Mean Squared Error:', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
